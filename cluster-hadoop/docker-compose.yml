services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    hostname: namenode
    environment:
      - CLUSTER_NAME=hadoop-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    ports:
      - "9870:9870"
      - "9000:9000"
    volumes:
      - namenode-data:/hadoop/dfs/name
    networks:
      - hadoop-network

  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode1
    hostname: datanode1
    depends_on:
      - namenode
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    ports:
      - "9864:9864"
    volumes:
      - datanode1-data:/hadoop/dfs/data
    networks:
      - hadoop-network

  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode2
    hostname: datanode2
    depends_on:
      - namenode
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    ports:
      - "9865:9864"
    volumes:
      - datanode2-data:/hadoop/dfs/data
    networks:
      - hadoop-network

  datanode3:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode3
    hostname: datanode3
    depends_on:
      - namenode
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    ports:
      - "9866:9864"
    volumes:
      - datanode3-data:/hadoop/dfs/data
    networks:
      - hadoop-network

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    hostname: resourcemanager
    depends_on:
      - namenode
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
    ports:
      - "8088:8088"
    networks:
      - hadoop-network

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager1
    hostname: nodemanager1
    depends_on:
      - resourcemanager
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
    ports:
      - "8042:8042"
    networks:
      - hadoop-network

  nodemanager2:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager2
    hostname: nodemanager2
    depends_on:
      - resourcemanager
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
    ports:
      - "8043:8042"
    networks:
      - hadoop-network
  postgres:
    image: postgres:13
    container_name: postgres
    hostname: postgres
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hivepassword
    volumes:
      - hive-metastore-db:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - hadoop-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hive -d metastore"]
      interval: 10s
      timeout: 5s
      retries: 5

  hive-metastore:
    image: apache/hive:4.0.0
    container_name: hive-metastore
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      HIVE_METASTORE_DB_HOST: postgres
      HIVE_METASTORE_DB_PORT: 5432
      HIVE_METASTORE_DB_NAME: metastore
      HIVE_METASTORE_DB_USER: hive
      HIVE_METASTORE_DB_PASSWORD: hivepassword

      HIVE_METASTORE_PORT: 9083
      HIVE_METASTORE_URIS: thrift://hive-metastore:9083
      SERVICE_NAME: metastore

    ports:
      - "9083:9083"
    networks:
      - hadoop-network

  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    hostname: hive-server
    depends_on:
      hive-metastore:
        condition: service_started
    environment:
      SERVICE_NAME: hiveserver2
      CORE_CONF_fs_defaultFS: hdfs://namenode:9000
      SERVICE_OPTS: "-Dhive.metastore.uris=thrift://hive-metastore:9083"
    volumes:
      - ./hive/conf/hive-site.xml:/opt/hive/conf/hive-site.xml
      - ./hive/conf/log4j2.properties:/opt/hive/conf/log4j2.properties
    ports:
      - "10000:10000"
      - "10002:10002"
    networks:
      - hadoop-network

  spark-master:
    image: apache/spark:3.5.1
    hostname: spark-master
    container_name: spark-master
    ports:
      - "8085:8080"
      - "7077:7077"
    volumes:
      - spark-logs:/opt/spark/logs
    networks:
      - hadoop-network
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master

  spark-worker1:
    image: apache/spark:3.5.1
    hostname: spark-worker1
    container_name: spark-worker1
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_MEMORY: 2g
      SPARK_WORKER_CORES: 2
    ports:
      - "8081:8081"
    networks:
      - hadoop-network
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  spark-worker2:
    image: apache/spark:3.5.1
    hostname: spark-worker2
    container_name: spark-worker2
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_MEMORY: 2g
      SPARK_WORKER_CORES: 2
    ports:
      - "8082:8082"
    networks:
      - hadoop-network
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  pgadmin-hadoop:
    image: dpage/pgadmin4
    container_name: pgadmin-hadoop
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    networks:
      - hadoop-network
    depends_on:
      - postgres


networks:
  hadoop-network:
    external: true

volumes:
  namenode-data:
  datanode1-data:
  datanode2-data:
  datanode3-data:
  hive-metastore-db:
  spark-logs:
